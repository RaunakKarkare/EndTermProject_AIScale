{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcf8b4d",
   "metadata": {},
   "source": [
    "# Data download, preprocessing (Cleaning & Encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Large Dataset Handling\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "csv_file_path = \"survey.csv\"\n",
    "train_df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "train_df.printSchema()\n",
    "train_df.show(5)\n",
    "\n",
    "train_pd_df = train_df.toPandas()\n",
    "\n",
    "\n",
    "# there is no use of comments, state, Timestamp etc removing them\n",
    "\n",
    "train_pd_df = train_pd_df.drop(['comments'], axis= 1)\n",
    "train_pd_df = train_pd_df.drop(['state'], axis= 1)\n",
    "train_pd_df = train_pd_df.drop(['Timestamp'], axis= 1)\n",
    "\n",
    "\n",
    "train_pd_df.head(5)\n",
    "\n",
    "\n",
    "# Assign default values for each data type\n",
    "\n",
    "defaultInt = 0\n",
    "defaultString = 'NaN'\n",
    "defaultFloat = 0.0\n",
    "\n",
    "# Create lists by data type\n",
    "\n",
    "intFeatures = ['Age']\n",
    "stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere',\n",
    "                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',\n",
    "                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',\n",
    "                 'seek_help']\n",
    "floatFeatures = []\n",
    "\n",
    "# Clean the NaN's\n",
    "\n",
    "for feature in train_pd_df:\n",
    "    if feature in intFeatures:\n",
    "        train_pd_df[feature] = train_pd_df[feature].fillna(defaultInt)\n",
    "    elif feature in stringFeatures:\n",
    "        train_pd_df[feature] = train_pd_df[feature].fillna(defaultString)\n",
    "    elif feature in floatFeatures:\n",
    "        train_pd_df[feature] = train_pd_df[feature].fillna(defaultFloat)\n",
    "    else:\n",
    "        print('Error: Feature %s not recognized.' % feature)\n",
    "train_pd_df.head(5)   \n",
    "\n",
    "#clean 'Gender'\n",
    "#Slower case all columm's elements\n",
    "gender = train_pd_df['Gender'].str.lower()\n",
    "#print(gender)\n",
    "\n",
    "#Select unique elements\n",
    "gender = train_pd_df['Gender'].unique()\n",
    "\n",
    "#Made gender groups\n",
    "male_str = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \"cis male\"]\n",
    "trans_str = [\"trans-female\", \"something kinda male?\", \"queer/she/they\", \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \"genderqueer\", \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \"trans woman\", \"neuter\", \"female (trans)\", \"queer\", \"ostensibly male, unsure what that really means\"]           \n",
    "female_str = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
    "\n",
    "for (row, col) in train_pd_df.iterrows():\n",
    "\n",
    "    if str.lower(col.Gender) in male_str:\n",
    "        train_pd_df['Gender'].replace(to_replace=col.Gender, value='male', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in female_str:\n",
    "        train_pd_df['Gender'].replace(to_replace=col.Gender, value='female', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in trans_str:\n",
    "        train_pd_df['Gender'].replace(to_replace=col.Gender, value='trans', inplace=True)\n",
    "\n",
    "#Getting rid of gender's other than male, female, trans\n",
    "stk_list = ['A little about you', 'p']\n",
    "train_pd_df = train_pd_df[~train_pd_df['Gender'].isin(stk_list)]\n",
    "\n",
    "print(train_pd_df['Gender'].unique())\n",
    "\n",
    "#complete missing age with mean\n",
    "train_pd_df['Age'].fillna(train_pd_df['Age'].median(), inplace = True)\n",
    "\n",
    "# Fill with media() values < 18 and > 120\n",
    "\n",
    "s = pd.Series(train_pd_df['Age'])\n",
    "s[s<18] = train_pd_df['Age'].median()\n",
    "train_pd_df['Age'] = s\n",
    "s = pd.Series(train_pd_df['Age'])\n",
    "s[s>120] = train_pd_df['Age'].median()\n",
    "train_pd_df['Age'] = s\n",
    "\n",
    "#Ranges of Age\n",
    "train_pd_df['age_range'] = pd.cut(train_pd_df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)\n",
    "\n",
    "#Replace self_employed= \"NaN\"  to NA\n",
    "train_pd_df['self_employed'] = train_pd_df['self_employed'].replace([defaultString], 'No')\n",
    "print(train_pd_df['self_employed'].unique())\n",
    "\n",
    "#Replace work_interface= \"NaN\"  to NA\n",
    "\n",
    "\n",
    "train_pd_df['work_interfere'] = train_pd_df['work_interfere'].replace([defaultString], 'Don\\'t know' )\n",
    "print(train_pd_df['work_interfere'].unique())\n",
    "\n",
    "#Encoding data\n",
    "\n",
    "labelDict = {}\n",
    "for feature in train_pd_df:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_pd_df[feature])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    train_pd_df[feature] = le.transform(train_pd_df[feature])\n",
    "    # Get labels\n",
    "    labelKey = 'label_' + feature\n",
    "    labelValue = [*le_name_mapping]\n",
    "    labelDict[labelKey] =labelValue\n",
    "    \n",
    "for key, value in labelDict.items():     \n",
    "    print(key, value)\n",
    "\n",
    "# Dropping 'country' as we already have label_country\n",
    "\n",
    "train_pd_df = train_pd_df.drop(['Country'], axis= 1)\n",
    "train_pd_df.head()\n",
    "\n",
    "# checking missing data %\n",
    "\n",
    "total = train_pd_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_pd_df.isnull().sum()/train_pd_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410da939",
   "metadata": {},
   "source": [
    "# EDA and data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(train_pd_df)\n",
    "clean_data_file_path = \"cleaned_data.csv\"\n",
    "spark_df.write.csv(clean_data_file_path, mode='overwrite')\n",
    "\n",
    "#correlation matrix\n",
    "corrmat = train_pd_df.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "plt.show()\n",
    "\n",
    "\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'treatment')['treatment'].index\n",
    "cm = np.corrcoef(train_pd_df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribiution and density by Age\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_pd_df[\"Age\"], bins=24)\n",
    "plt.title(\"Distribuition and density by Age\")\n",
    "plt.xlabel(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate by treatment or not\n",
    "\n",
    "g = sns.FacetGrid(train_pd_df, col='treatment', height=5)\n",
    "g = g.map(sns.distplot, \"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let see how many people has been treated\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "new_labels = ['Men', 'Women']\n",
    "g = sns.countplot(x=\"treatment\", data=train_pd_df)\n",
    "g.set_xticklabels(new_labels)\n",
    "\n",
    "plt.title('Total Distribuition by treated or not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d24af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#barplot to show probabilities for class and sex\n",
    "\n",
    "o = labelDict['label_age_range']\n",
    "\n",
    "g = sns.barplot(x=\"age_range\", y=\"treatment\", hue=\"Gender\", data=train_pd_df,  ci=None )\n",
    "g.set_xticklabels(o)\n",
    "\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Age')\n",
    "# replace legend labels\n",
    "\n",
    "new_labels = labelDict['label_Gender']\n",
    "legend = g.get_legend()\n",
    "\n",
    "for t, l in zip(legend.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot of family history vs gender\n",
    "o = labelDict['label_family_history']\n",
    "g = sns.barplot(x=\"family_history\", y=\"treatment\", hue=\"Gender\", data=train_pd_df, ci=None)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Family History')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "legend = g.get_legend()\n",
    "\n",
    "for t, l in zip(legend.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot of care options vs gender\n",
    "\n",
    "o = labelDict['label_care_options']\n",
    "g = sns.barplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_pd_df, ci=None)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Care options')\n",
    "\n",
    "new_labels = labelDict['label_Gender']\n",
    "legend = g.get_legend()\n",
    "\n",
    "for t, l in zip(legend.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot of benefits vs gender \n",
    "\n",
    "o = labelDict['label_benefits']\n",
    "g = sns.barplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_pd_df, ci=None)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Benefits')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "legend = g.get_legend()\n",
    "\n",
    "for t, l in zip(legend.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot of work interference vs gender\n",
    "\n",
    "o = labelDict['label_work_interfere']\n",
    "g = sns.barplot(x=\"work_interfere\", y=\"treatment\", hue=\"Gender\", data=train_pd_df, ci=None)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Work interfere')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "legend = g.get_legend()\n",
    "\n",
    "for t, l in zip(legend.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Age\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_pd_df['Age'] = scaler.fit_transform(train_pd_df[['Age']])\n",
    "train_pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904aeb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(train_pd_df)\n",
    "parquet_file_path = \"processed_data.parquet\"\n",
    "spark_df.write.parquet(parquet_file_path, mode='overwrite')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.read.parquet(\"processed_data.parquet\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d410e",
   "metadata": {},
   "source": [
    "# AutoML with TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccad13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "# define X and y\n",
    "feature_cols = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.treatment\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Create dictionaries for final graph\n",
    "# Use: methodDict['Stacking'] = accuracy_score\n",
    "methodDict = {}\n",
    "rmseDict = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing feature importance\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "labels = []\n",
    "for f in range(X.shape[1]):\n",
    "    labels.append(feature_cols[f])      \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), labels, rotation='vertical')\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Step 3: Configure TPOT\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "\n",
    "# Step 4: Fit TPOT on the training data\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Export the best model\n",
    "tpot.export('tpot_best_model.py')\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = tpot.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96937922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
